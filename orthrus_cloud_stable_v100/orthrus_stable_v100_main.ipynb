{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOozu2zCtsI4boYG8tu3o8M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yc386/orthrus_metaproteomics/blob/main/orthrus_cloud_stable_v100/orthrus_stable_v100_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://drive.google.com/uc?export=view&id=19rmmQI1H2nIqgU598WROTcUNhOUoXcBP' width='400px' align='right'>\n",
        "\n",
        "# **Readme**\n",
        "\n",
        "---\n",
        "[Orthrus](https://www.biorxiv.org/content/10.1101/2024.11.15.623814v1) üêæ is a hybrid, two-software pipeline that integrates [Casanovo](https://github.com/Noble-Lab/casanovo) (an AI transformer) with [Sage](https://github.com/lazear/sage) (a fast database search engine with advanced features like retention time alignment and machine learning-based rescoring).\n",
        "\n",
        "Designed to handle large search spaces in metaproteomics and palaeoproteomics, Orthrus leverages *de novo* sequencing to define sample-specific databases, and uses probability ranking and conventional database searching to control FDRs (false discovery rates).\n",
        "\n",
        "This notebook is optimised for Google Colab ü•≥\n",
        "\n",
        "# **Quick start**‚ùóÔ∏è\n",
        "1. Before walking the dog, please change the runtime type to GPU (A100, L4, or T4. A100 most efficient but T4 is free)\n",
        "2. Click the folder image üóÇÔ∏è on the left and mount your Google drive (permission pending)\n",
        "3. Click `File` (top left) to save a local copy\n",
        "4. **Run the `Install everything, will automatically restart` cell first and wait for restarting (until you see {'status': 'ok', 'restart': True})**, to resolve the numpy+pandas version conflicts. Casanovo 4x and Mokapot require numpy 1x\n",
        "5. After restarting, choose, Casanovo, Sage, and Mokapot configurations. Then **from the `Configure Casanovo` cell, click `Runtime` -> `Run cell and below`**"
      ],
      "metadata": {
        "id": "GSluwkjnXBed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install everything, will **automatically restart** to resolve version conflicts\n",
        "\n",
        "import os, sys, subprocess, time, IPython\n",
        "from pathlib import Path\n",
        "if not Path(\"Orthrus_READY\").exists():\n",
        "    print(\"installing Sage binary and packagesüì¶ ‚¨áÔ∏è\")\n",
        "    #Sage version 0.14.7\n",
        "    !wget -q https://github.com/lazear/sage/releases/download/v0.14.7/sage-v0.14.7-x86_64-unknown-linux-gnu.tar.gz\n",
        "    !tar -xzf sage-v0.14.7-x86_64-unknown-linux-gnu.tar.gz && rm sage-v0.14.7-x86_64-unknown-linux-gnu.tar.gz\n",
        "    pip_packages = [\"casanovo==4.3.0\", \"biopython==1.85\", \"pyteomics==4.7.5\", \"mokapot==0.10.0\", \"numpy==1.26.4\", \"pandas==2.1.4\", \"xgboost==3.0.4\", \"rich[jupyter]\"]\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\",\n",
        "                           *pip_packages])\n",
        "    Path(\"Orthrus_READY\").touch()\n",
        "else:\n",
        "    print(\"Environment already prepared.\")\n",
        "\n",
        "msg = \"Restarting ü´® ‚û°Ô∏è Don't click any Google prompts\"\n",
        "print(msg, flush=True)\n",
        "time.sleep(0.5)\n",
        "IPython.Application.instance().kernel.do_shutdown(restart=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2JVxR1gOW_GU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Configure `Casanovo`\n",
        "#@markdown **`Casanovo` inputs**\n",
        "folder_path=\"\"#@param {type:\"string\"}\n",
        "#@markdown - a folder contains single or multiple `.mzML` or `.mgf` files for `Casanovo`. Please check only _ (underscore) and no other special characters or space in a file name. **Ensure all instrument files in a single folder and no other subfolders in that parent folder.**\n",
        "file_type=\"mzML\" #@param [\"mzML\", \"mgf\"]\n",
        "#@markdown - use the drop-down menu to choose the instrument file type\n",
        "\n",
        "use_default = True #@param {type:\"boolean\"}\n",
        "#@markdown - use the default model + configuration yaml from `Casanovo` github repo, may take time to download\n",
        "\n",
        "#@markdown **Advanced Options (user provided model + configuration yaml)**\n",
        "\n",
        "model = \"\" #@param {type:\"string\"}\n",
        "#@markdown - a `.ckpt` trained model (check point)\n",
        "config = \"\" #@param {type:\"string\"}\n",
        "#@markdown - a `.yaml` configuration file (see config_420_precursor_7_ppm.yaml)\n",
        "\n",
        "#@markdown **Inputs for converting Casanovo results to a `.fasta`**\n",
        "use_SwissProt = True #@param {type:\"boolean\"}\n",
        "#@markdown - use the latest, reviewed SwissProt form the UniProt FTP\n",
        "database_path=\"\"#@param {type:\"string\"}\n",
        "#@markdown - path to a user-defined database (`.fasta`)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zOZ-x1KlXH-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Configure `SAGE`\n",
        "json_file_path = '' #@param {type:\"string\"}\n",
        "#@markdown - a configuration `.json` file (see config_general_MQ_fixed_CAM_v1.json)\n",
        "enzyme = \"KR\" #@param {type:\"string\"}\n",
        "#@markdown **`SAGE` PTM plus**\n",
        "#@markdown - Default `Sage` contains CAM (fixed) (+57.021464) + variable mods: Oxidation(M) (+15.994915), Deamidation(NQ) (+0.984016)\n",
        "#@markdown - PTM plus up to 5 variable mods and CAM (cysteine carbamidomethylation) can be turned off\n",
        "#@markdown - PTM mass can be any decimals\n",
        "use_PTM_plus = False #@param {type:\"boolean\"}\n",
        "static_CAM = True #@param {type:\"boolean\"}\n",
        "max_variable_mods = 3 #@param {type: \"number\"}\n",
        "#@markdown - please note `SAGE` only allow max 3 variable mods per PSM\n",
        "missed_cleavages = 2 #@param {type:\"number\"}\n",
        "AA_1 = \"M\" #@param [\"None\", \"[\",\"]\",\"A\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\", \"M\", \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"W\", \"Y\"]\n",
        "AA_1_mod = 15.9949 #@param {type:\"number\"}\n",
        "AA_2 = \"P\" #@param [\"None\", \"[\",\"]\",\"A\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\", \"M\", \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"W\", \"Y\"]\n",
        "AA_2_mod = 15.9949 #@param {type:\"number\"}\n",
        "AA_3 = \"N\" #@param [\"None\", \"[\",\"]\",\"A\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\", \"M\", \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"W\", \"Y\"]\n",
        "AA_3_mod = 0.984016 #@param {type:\"number\"}\n",
        "AA_4 = \"Q\" #@param [\"None\", \"[\",\"]\",\"A\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\", \"M\", \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"W\", \"Y\"]\n",
        "AA_4_mod = 0.984016 #@param {type:\"number\"}\n",
        "AA_5 = \"[\" #@param [\"None\", \"[\",\"]\",\"A\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\", \"M\", \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"W\", \"Y\"]\n",
        "#@markdown - [ = n-terminal\n",
        "AA_5_mod = \t42.010565 #@param {type:\"number\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zV_HSAFQXRb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Configure `Mokapot`\n",
        "\n",
        "joint_modelling= True #@param {type:\"boolean\"}\n",
        "#@markdown - a joint model for low abundance samples, unclick for a separate model per experiment\n",
        "default_Percolator=True #@param {type:\"boolean\"}\n",
        "#@markdown - Python implementation of the Percolator SVM model, otherwise the non-linear XGBoost model"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9z_KvtzFXW4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title import functions\n",
        "\n",
        "# ----------------------------- Utility Setup ------------------------------- #\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "# Python standards\n",
        "import argparse\n",
        "import datetime\n",
        "import glob\n",
        "import gzip\n",
        "import io\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import subprocess\n",
        "import sys\n",
        "import time\n",
        "import warnings\n",
        "from contextlib import redirect_stderr, redirect_stdout\n",
        "from itertools import chain\n",
        "from typing import Dict, List, Optional, Set\n",
        "\n",
        "# 3rd part from pip etc\n",
        "from rich.logging import RichHandler\n",
        "from rich.traceback import install as install_rich_traceback\n",
        "import mokapot\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "from Bio import SeqIO\n",
        "from Bio.Seq import Seq\n",
        "from Bio.SeqRecord import SeqRecord\n",
        "from joblib import Parallel, delayed\n",
        "from pyteomics import mztab\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "#for logging\n",
        "LOGGER = logging.getLogger(\"orthrus_metaproteomics\")\n",
        "#quieter outputs\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "def initiate_logger(level: str = \"INFO\",\n",
        "                    name_color: str = \"#00D1FF\"):\n",
        "    #use Rich to add colours to logging, hex code version\n",
        "    install_rich_traceback(show_locals=False)\n",
        "    numeric = getattr(logging, level.upper(), logging.INFO)\n",
        "    logger = globals().get(\"LOGGER\", logging.getLogger())\n",
        "    logger.setLevel(numeric)\n",
        "    logger.handlers.clear()\n",
        "    logger.propagate = False\n",
        "\n",
        "    console = RichHandler(\n",
        "        level=numeric,\n",
        "        show_time=True,\n",
        "        show_level=True,\n",
        "        show_path=False,\n",
        "        markup=True,\n",
        "        rich_tracebacks=True,\n",
        "        log_time_format=\"%Y-%m-%d %H:%M:%S\",\n",
        "    )\n",
        "    console.setFormatter(logging.Formatter(f\"[bold {name_color}]%(name)s[/] | %(message)s\"))\n",
        "    logger.addHandler(console)\n",
        "\n",
        "    logging.getLogger(\"mokapot\").setLevel(logging.ERROR)\n",
        "\n",
        "    return logger\n",
        "\n",
        "\n",
        "log = initiate_logger(\"INFO\", name_color=\"#03cafc\")\n",
        "\n",
        "\n",
        "# Casanovo 4x column names\n",
        "mztab_seq_col = 'sequence'\n",
        "score_col = 'search_engine_score[1]'\n",
        "\n",
        "\n",
        "def prep_mztab(mztab_path: str):\n",
        "    # mztab -> pd.Dataframe\n",
        "    log.info(\"Reading mzTab: %s\", mztab_path)\n",
        "    m = mztab.MzTab(mztab_path)\n",
        "    df = m.spectrum_match_table\n",
        "    if df is None or df.empty:\n",
        "        raise ValueError(f\"{mztab_path} is empty\")\n",
        "    if mztab_seq_col not in df.columns:\n",
        "        raise KeyError(f\"'{mztab_seq_col}' column is missing in the file: {mztab_path}\")\n",
        "    df1 = df.reset_index(drop=True)\n",
        "    #^[+-]?\\d+(?:\\.\\d+)?) for n-terminal mods\n",
        "    df2 = df1.assign(sequence_naked=df1[mztab_seq_col].str.replace(r'(?:(?<=[A-Z])[+-]?\\d+(?:\\.\\d+)?|^[+-]?\\d+(?:\\.\\d+)?)', '', regex=True))\n",
        "    df3= df2.assign(nAA=df2['sequence_naked'].str.len())\n",
        "    df4=df3.sort_values(by='sequence_naked').drop_duplicates(subset='sequence_naked', keep=\"first\").reset_index(drop=True)\n",
        "    log.debug(\"mzTab prepped: %d unique naked sequences\", df4.shape[0])\n",
        "    return df4\n",
        "\n",
        "\n",
        "def fasta_to_df(fasta_file: str):\n",
        "    # fasta -> pd.Dataframe\n",
        "    log.info(\"Reading FASTA: %s\", fasta_file)\n",
        "    data = []\n",
        "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
        "        protein_id = record.id\n",
        "        description = record.description\n",
        "        sequence = str(record.seq)\n",
        "        if not sequence:\n",
        "            raise ValueError(f\"Record with ID '{protein_id}' has no sequence in the fasta file.\")\n",
        "        data.append((protein_id, description, sequence))\n",
        "    df = pd.DataFrame(data, columns=[\"Protein_ID\", \"Description\", \"Sequence\"])\n",
        "    df1=df.assign(UniProt_ID=df['Protein_ID'].str.split('|').str[1])\n",
        "    log.debug(\"FASTA prepped: %d protein entries\", df1.shape[0])\n",
        "    return df1\n",
        "\n",
        "\n",
        "# filter casanovo outputs using the maximum score below zero\n",
        "def casa_filter(df):\n",
        "    if score_col not in df.columns:\n",
        "        raise KeyError(f\"'{score_col}' not found\")\n",
        "    np_array = df[score_col].to_numpy()\n",
        "    max_below_zero = np_array[np_array < 0].max()\n",
        "    df1=df[df[score_col]>=max_below_zero]\n",
        "    log.info(\n",
        "        \"casa_filter: kept %d/%d PSMs (threshold=%.6f)\",\n",
        "        df1.shape[0],\n",
        "        df.shape[0],\n",
        "        max_below_zero)\n",
        "    return df1\n",
        "\n",
        "\n",
        "# ----------------------------- matching & Bayes ranking ------------------------------- #\n",
        "\n",
        "\n",
        "#prepare overlapping sequence tags for string matching\n",
        "def get_seq_tags(sequence: str, k: int):\n",
        "    return set(sequence[i:i+k] for i in range(len(sequence) - k + 1))\n",
        "\n",
        "\n",
        "#change chunk size here for memory if needed\n",
        "def matching_count_v5(fasta_df: pd.DataFrame, casanovo_df: pd.DataFrame, k: int, chunk_size: int=10000):\n",
        "    log.info(\"Generating sequence tags (k=%d)...\", k)\n",
        "    sequence_set = get_seq_tags(''.join(chain.from_iterable(casanovo_df['sequence_naked'].astype(str))), k)\n",
        "    log.info(\"Generated %d unique tags from Casanovo outputs.\", len(sequence_set))\n",
        "    result_df = pd.DataFrame()\n",
        "    for start in range(0, len(fasta_df), chunk_size):\n",
        "        chunk = fasta_df.iloc[start:start+chunk_size].copy()\n",
        "        chunk['seq_tags'] = chunk['Sequence'].astype(str).str.replace('I', 'L').apply(lambda x: get_seq_tags(x, k))\n",
        "        chunk['matched_count'] = chunk['seq_tags'].apply(lambda seq_tags: len(seq_tags & sequence_set))\n",
        "        chunk = chunk.assign(matched=chunk['matched_count'].apply(lambda x: 1 if x >= 2 else 0))\n",
        "        result_df = pd.concat([result_df, chunk], ignore_index=True)\n",
        "    log.info(\n",
        "        \"Tag matching complete: total matched tag counts=%d\",\n",
        "        int(result_df[\"matched_count\"].sum()))\n",
        "    return result_df\n",
        "\n",
        "\n",
        "#get tryptic peptides per database entry\n",
        "def count_tryptic_peptides(sequence: str):\n",
        "    pattern=r'(?<=[KR])'\n",
        "    peptides = re.split(pattern, sequence)\n",
        "    filtered_peptides = [peptide for peptide in peptides if len(peptide) >= 6]\n",
        "    return len(filtered_peptides)\n",
        "\n",
        "\n",
        "#prepare a dataframe for NB classification\n",
        "def prep_Bayes(df: pd.DataFrame):\n",
        "    df1=df.assign(length=df['Sequence'].astype(str).str.len(),\n",
        "                 tryptic_count=df['Sequence'].apply(count_tryptic_peptides),\n",
        "                 tag_count=df['seq_tags'].apply(len))\n",
        "    df2=df1.assign(SAF=df1['matched_count']/df1['length'],\n",
        "                 try_ratio=df1['tryptic_count']/df1['tag_count'])\n",
        "    return df2\n",
        "\n",
        "\n",
        "# bayes ranking\n",
        "def get_bayes_ranking_test(df: pd.DataFrame, threshold: float = 0.95):\n",
        "    m=prep_Bayes(df)\n",
        "    required_columns = {'SAF', 'try_ratio', 'matched'}\n",
        "    if not required_columns.issubset(m.columns):\n",
        "        missing = required_columns - set(m.columns)\n",
        "        raise ValueError(f\"Missing columns in DataFrame: {missing}\")\n",
        "    m1 = m[m['tag_count']>0]\n",
        "    X = m1[['SAF', 'try_ratio']].to_numpy()\n",
        "    y = m1['matched'].to_numpy()\n",
        "    scaler = MinMaxScaler()\n",
        "    X_scaled = scaler.fit_transform(X.reshape(-1, 1)).reshape(*X.shape)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=7)\n",
        "    gnb = GaussianNB()\n",
        "    gnb.fit(X_train, y_train)\n",
        "    y_pred = gnb.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    log.info(\"GaussianNB ‚ñ∂ accuracy=%.4f, precision=%.4f, f1=%.4f\", accuracy, precision, f1)\n",
        "    whole_pred = gnb.predict(X_scaled)\n",
        "    class_probabilities = gnb.predict_proba(X_scaled)\n",
        "    m2 = m1.assign(pred=class_probabilities[:, 1])\n",
        "    m3 = m2[m2['pred']>=threshold]\n",
        "    log.info(\"Shortlisted %d proteins at ‚â• %.2f.\", m3.shape[0], threshold)\n",
        "    return m3\n",
        "\n",
        "\n",
        "# ----------------------------- De novo -> sample-specific .fastas ------------------------------- #\n",
        "\n",
        "\n",
        "def matching_ranking_to_fasta_v5(mztab_path: str, fasta_df: pd.DataFrame):\n",
        "    p = prep_mztab(mztab_path)\n",
        "    casanovo_df = casa_filter(p)\n",
        "    k = int(casanovo_df['nAA'].median())\n",
        "    m = matching_count_v5 (fasta_df, casanovo_df, k, chunk_size=10000)\n",
        "    m1 = get_bayes_ranking_test (m)\n",
        "    seq_records = []\n",
        "    for index, row in m1.iterrows():\n",
        "        header_id = f\"{row['Description']}\"\n",
        "        sequence = Seq(row['Sequence'])\n",
        "        description = \"\"\n",
        "        seq_record = SeqRecord(sequence, id=header_id, description=description)\n",
        "        seq_records.append(seq_record)\n",
        "\n",
        "    output_fasta_filepath = mztab_path.replace('.mztab', '_matched.fasta')\n",
        "\n",
        "    with open(output_fasta_filepath, 'w') as output_file:\n",
        "        SeqIO.write(seq_records, output_file, 'fasta')\n",
        "    log.info(\"Wrote matched FASTA %s (entries=%d)\", output_fasta_filepath, m1.shape[0])\n",
        "\n",
        "\n",
        "def process_all_mztab_files_v2(folder_path: str, database_path: str):\n",
        "    mztab_filepaths = glob.glob(f\"{folder_path}/*.mztab\")\n",
        "    log.info(\"Found %d mzTab file(s) in %s\", len(mztab_filepaths), folder_path)\n",
        "    fasta_df=fasta_to_df(database_path)\n",
        "    log.info(\"Reference FASTA loaded from %s (proteins=%d)\", database_path, fasta_df.shape[0])\n",
        "    for mztab in mztab_filepaths:\n",
        "        matching_ranking_to_fasta_v5 (mztab, fasta_df)\n",
        "\n",
        "\n",
        "# ----------------------------- utilities for Sage ------------------------------- #\n",
        "\n",
        "\n",
        "def organise_files(directory: str, file_type: str):\n",
        "    if not os.path.isdir(directory):\n",
        "        log.error(\"Directory does not exist: %s\", directory)\n",
        "        return\n",
        "\n",
        "    MS2_files = glob.glob(os.path.join(directory, f'*.{file_type}'))\n",
        "    if not MS2_files:\n",
        "        log.warning(\"No %s files found in %s, or files already organised\", file_type, directory)\n",
        "    for MS2 in MS2_files:\n",
        "        log.info(\"Organising files in %s ...\", directory)\n",
        "        base_name = os.path.splitext(os.path.basename(MS2))[0]\n",
        "        new_folder_path = os.path.join(directory, base_name)\n",
        "        if not os.path.exists(new_folder_path):\n",
        "            os.makedirs(new_folder_path)\n",
        "\n",
        "        MS2_path = os.path.join(new_folder_path, os.path.basename(MS2))\n",
        "        if not os.path.exists(MS2_path):\n",
        "            shutil.move(MS2, new_folder_path)\n",
        "            log.info(\"Moved %s to %s\", MS2, new_folder_path)\n",
        "        else:\n",
        "            log.warning(\"MS2 file already exists in the destination: %s\", MS2_path)\n",
        "\n",
        "        fasta_filename = f\"{base_name}_matched.fasta\"\n",
        "        fasta_file = os.path.join(directory, fasta_filename)\n",
        "        if os.path.exists(fasta_file):\n",
        "            new_fasta_path = os.path.join(new_folder_path, fasta_filename)\n",
        "            if not os.path.exists(new_fasta_path):\n",
        "                shutil.move(fasta_file, new_folder_path)\n",
        "                log.info(\"Moved %s to %s\", fasta_file, new_folder_path)\n",
        "            else:\n",
        "                log.info(\".fasta file already exists in the destination: %s\", new_fasta_path)\n",
        "        else:\n",
        "            log.warning(\"No matching .fasta file found for %s\", base_name)\n",
        "\n",
        "\n",
        "def get_sage_config(json_file_path: str,\n",
        "                    peak_path: Union[str, List[str]],\n",
        "                    static_mods: Dict[str, float],\n",
        "                    new_mods: Dict[str, List[float]],\n",
        "                    missed_cleavages: int,\n",
        "                    enzyme: str,\n",
        "                    min_len: int,\n",
        "                    max_len: int,\n",
        "                    max_variable_mods: int,\n",
        "                    output_config_path: str):\n",
        "\n",
        "    with open(json_file_path, 'r') as file:\n",
        "        json_data = json.load(file)\n",
        "        if isinstance(peak_path, str):\n",
        "            peak_path = [peak_path]\n",
        "\n",
        "        json_data['mzml_paths'] = peak_path\n",
        "        json_data['database']['static_mods'] = static_mods\n",
        "        json_data['database']['variable_mods'] = new_mods\n",
        "        json_data['database']['enzyme']['missed_cleavages'] = missed_cleavages\n",
        "        json_data['database']['enzyme']['cleave_at']= enzyme\n",
        "        json_data['database']['enzyme']['min_len'] = min_len\n",
        "        json_data['database']['enzyme']['max_len'] = max_len\n",
        "        json_data['database']['max_variable_mods'] = max_variable_mods\n",
        "        json_data['database']['decoy_tag'] = \"rev_\"\n",
        "        json_data['database']['generate_decoys'] = True\n",
        "\n",
        "    with open(output_config_path, 'w') as f:\n",
        "        json.dump(json_data, f, indent=4)\n",
        "    log.info(\"Wrote Sage config: %s\", output_config_path)"
      ],
      "metadata": {
        "id": "dKIJMVWA522M",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run `Casanovo`\n",
        "\n",
        "def run_casanovo(\n",
        "        folder_path: str,\n",
        "        file_type: str,\n",
        "        use_default: bool,\n",
        "        model: Optional[str] = None,\n",
        "        config: Optional[str] = None):\n",
        "    files = glob.glob(f\"{folder_path}/*.{file_type}\")\n",
        "    if not files:\n",
        "        log.error(\"No instrument files found in %s with extension .%s\", folder_path, file_type)\n",
        "        return\n",
        "\n",
        "    env = os.environ.copy()\n",
        "    env[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "    env[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n",
        "\n",
        "    for instrument_file in files:\n",
        "        output_path=instrument_file.replace(f\".{file_type}\", \".mztab\")\n",
        "        if use_default:\n",
        "            cmd = [\"casanovo\", \"sequence\", instrument_file, \"-v\", \"info\", \"-o\", output_path]\n",
        "        else:\n",
        "            cmd= [\"casanovo\", \"sequence\", instrument_file, \"-m\", model, \"-c\", config, \"-v\", \"info\", \"-o\", output_path]\n",
        "        log.info(\"Running Casanovo: %s\", \" \".join(cmd))\n",
        "        subprocess.run(cmd,\n",
        "                       check=True,\n",
        "                       stdout=subprocess.DEVNULL,\n",
        "                       stderr=subprocess.DEVNULL,\n",
        "                       env=env)\n",
        "        log.info(\"Casanovo done üëç\")\n",
        "\n",
        "run_casanovo(folder_path, file_type, use_default, model, config)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Z5d2CcP-YB3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Convert `Casanovo` results to .fasta per experiment\n",
        "\n",
        "if use_SwissProt:\n",
        "    url = \"https://ftp.uniprot.org/pub/databases/uniprot/knowledgebase/complete/uniprot_sprot.fasta.gz\"\n",
        "    output_file = \"uniprot_sprot.fasta.gz\"\n",
        "    decompressed_file = \"uniprot_sprot.fasta\"\n",
        "    response = requests.get(url, stream=True)\n",
        "    if response.status_code == 200:\n",
        "        with open(output_file, 'wb') as f:\n",
        "            shutil.copyfileobj(response.raw, f)\n",
        "            log.info(\"%s downloaded successfully.\", output_file)\n",
        "    else:\n",
        "        log.error(\"Failed to download %s. Status code: %d\", output_file, response.status_code)\n",
        "\n",
        "    with gzip.open(output_file, 'rb') as f_in:\n",
        "        with open(decompressed_file, 'wb') as f_out:\n",
        "            shutil.copyfileobj(f_in, f_out)\n",
        "    sprot_path=\"uniprot_sprot.fasta\"\n",
        "    process_all_mztab_files_v2(folder_path, sprot_path)\n",
        "\n",
        "else:\n",
        "    process_all_mztab_files_v2(folder_path, database_path)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ptN8ow1gYC0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run `Sage`\n",
        "\n",
        "# colab version sage binary\n",
        "sage_path=\"/content/sage-v0.14.7-x86_64-unknown-linux-gnu/sage\"\n",
        "\n",
        "\n",
        "def run_sage (\n",
        "        folder_path: str,\n",
        "        file_type: str,\n",
        "        sage_path: str,\n",
        "        json_file_path: str,\n",
        "        enzyme: str,\n",
        "        use_PTM_plus: bool,\n",
        "        missed_cleavages: int,\n",
        "        max_variable_mods: int,\n",
        "        static_CAM: bool):\n",
        "\n",
        "    organise_files(folder_path, file_type)\n",
        "\n",
        "    if not (os.path.isfile(sage_path)):\n",
        "        log.error(\"Sage binary not found or not executable: %s\", sage_path)\n",
        "        return\n",
        "\n",
        "    # constants\n",
        "    min_len, max_len = 6, 30\n",
        "    static_mods = {\"C\": 57.021464} if static_CAM else {}\n",
        "    missed_cleavages = 2 if not use_PTM_plus else missed_cleavages\n",
        "    max_variable_mods = 3 if not use_PTM_plus else max_variable_mods\n",
        "    enzyme = enzyme\n",
        "\n",
        "    if use_PTM_plus:\n",
        "        AAs = [AA_1, AA_2, AA_3, AA_4, AA_5]\n",
        "        mods = [AA_1_mod, AA_2_mod, AA_3_mod, AA_4_mod, AA_5_mod]\n",
        "        PTMs = {}\n",
        "        for AA, mod in zip(AAs, mods):\n",
        "            if AA != \"None\":\n",
        "                PTMs[AA] = [mod]\n",
        "    else:\n",
        "        PTMs = {\"M\": [15.994915], \"N\": [0.984016], \"Q\": [0.984016]}\n",
        "\n",
        "    # iterate each sub-folder\n",
        "    big_folder = [p for p in glob.glob(f\"{folder_path}/*\") if os.path.isdir(p)]\n",
        "    if not big_folder:\n",
        "        log.warning(\"No subfolders found.\", RuntimeWarning)\n",
        "        return\n",
        "\n",
        "    for folder in big_folder:\n",
        "        files = glob.glob(f\"{folder}/*.{file_type}\")\n",
        "        if not files:\n",
        "            log.warning(\"No %s files in %s; skipping.\", file_type, folder)\n",
        "            continue\n",
        "\n",
        "        peak_path   = files[0]\n",
        "        output_json = peak_path.replace(f\".{file_type}\", \".json\")\n",
        "\n",
        "        get_sage_config(\n",
        "            json_file_path, peak_path, static_mods, PTMs,\n",
        "            missed_cleavages, enzyme,\n",
        "            min_len, max_len,\n",
        "            max_variable_mods, output_json\n",
        "        )\n",
        "\n",
        "        fasta_files = glob.glob(f\"{folder}/*.fasta\")\n",
        "        if not fasta_files:\n",
        "            log.warning(\"No FASTA in %s.\", folder)\n",
        "            continue\n",
        "\n",
        "        fasta_path = fasta_files[0]\n",
        "        cmd = [sage_path, output_json, \"--fasta\", fasta_path,\n",
        "               \"--write-pin\",\n",
        "               \"--output_directory\", folder\n",
        "               ]\n",
        "        log.info(\"Running Sage for %s\", folder)\n",
        "        subprocess.run(cmd,\n",
        "                       check=True,\n",
        "                       stdout=subprocess.DEVNULL,\n",
        "                       stderr=subprocess.DEVNULL)\n",
        "        log.info(\"Sage finished casting spells üßô for %s\", folder)\n",
        "\n",
        "\n",
        "run_sage(\n",
        "    folder_path,\n",
        "    file_type,\n",
        "    sage_path,\n",
        "    json_file_path,\n",
        "    enzyme,\n",
        "    use_PTM_plus,\n",
        "    missed_cleavages,\n",
        "    max_variable_mods,\n",
        "    static_CAM)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7O0j-GqTYSpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Brew `Mokapot`\n",
        "\n",
        "\n",
        "def get_all_pin_files(folder_path):\n",
        "    psm_files = []\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            if file.endswith('.pin'):\n",
        "                full_path = os.path.join(root, file)\n",
        "                psm_files.append(full_path)\n",
        "    return psm_files\n",
        "\n",
        "\n",
        "def brew_mokapot(folder_path: str,\n",
        "                joint_modelling: bool,\n",
        "                default_Percolator: bool):\n",
        "    #XGBoost schema from Fondrie & Noble (2021).A non-linear XGBoost seems to be better for rescoring open search results.\n",
        "    grid = {\n",
        "        \"scale_pos_weight\": np.logspace(0, 2, 3),\n",
        "        \"max_depth\": [1, 3, 6],\n",
        "        \"min_child_weight\": [1, 10, 100],\n",
        "        \"gamma\": [0, 1, 10]}\n",
        "    xgb_mod = GridSearchCV(\n",
        "        XGBClassifier(),\n",
        "        param_grid=grid,\n",
        "        n_jobs=-1,\n",
        "        cv=3,\n",
        "        scoring=\"roc_auc\")\n",
        "\n",
        "    if joint_modelling:\n",
        "        psm_files = get_all_pin_files(folder_path)\n",
        "        if not psm_files:\n",
        "            log.warning(\"No .pin files found.\")\n",
        "            return\n",
        "        log.info(\"Brewing all .pins in folder: %s\", folder_path)\n",
        "        joint_psm_list = mokapot.read_pin(psm_files)\n",
        "        model = mokapot.PercolatorModel() if default_Percolator else mokapot.Model(xgb_mod)\n",
        "        with open(os.devnull, \"w\") as devnull, redirect_stdout(devnull), redirect_stderr(devnull):\n",
        "            results, models = mokapot.brew(joint_psm_list, model)\n",
        "        result_files = results.to_txt(folder_path)\n",
        "        log.info(\"Mokapot (joint modelling) brewed ‚òïÔ∏è (output: %s)\", folder_path)\n",
        "    else:\n",
        "        big_folder = [p for p in glob.glob(f\"{folder_path}/*\") if os.path.isdir(p)]\n",
        "        for folder in big_folder:\n",
        "            if not os.path.isdir(folder):\n",
        "                continue\n",
        "            log.info(\"Brewing folder: %s\", folder)\n",
        "            pin_files = glob.glob(f\"{folder}/*.pin\")\n",
        "            if not pin_files:\n",
        "                log.warning(\"No .pin files in %s; skipping.\", folder)\n",
        "                continue\n",
        "            pin = pin_files[0]\n",
        "            psm_list = mokapot.read_pin(pin)\n",
        "            model = mokapot.PercolatorModel() if default_Percolator else mokapot.Model(xgb_mod)\n",
        "            with open(os.devnull, \"w\") as devnull, redirect_stdout(devnull), redirect_stderr(devnull):\n",
        "                results, models = mokapot.brew(psm_list, model)\n",
        "            result_files = results.to_txt(folder)\n",
        "            log.info(\"Mokapot (single model per experiment) brewed ‚òïÔ∏è (output: %s)\", folder)\n",
        "\n",
        "\n",
        "brew_mokapot(folder_path,\n",
        "             joint_modelling,\n",
        "             default_Percolator)"
      ],
      "metadata": {
        "id": "EnLcyvqsYXbw",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}